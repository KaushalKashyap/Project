{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06529747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective for this Dataset:- we will use various predictive models to see how accurate, \n",
    "# they are in detecting whether we can correctly predict which comapnies will face bankrptcy or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27fb1c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "plt.rcParams['figure.figsize']=[15,7]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc, roc_curve, accuracy_score, recall_score, \n",
    "                             classification_report, f1_score, average_precision_score, precision_recall_fscore_support, \n",
    "                             roc_auc_score)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier \n",
    "import xgboost as XGB\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb7c3e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\VICTORS\\\\Desktop\\\\Project 2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "652424c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '_BANKRUPTCY_PREDICTION.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11008\\4164314709.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_BANKRUPTCY_PREDICTION.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '_BANKRUPTCY_PREDICTION.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"_BANKRUPTCY_PREDICTION.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07011e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the Descriptive statistics of our numerical features\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677ff9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a26c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc64942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Nan presence\n",
    "\n",
    "[print(col) for col in data if data[col].isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c09fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the uniqueness in the dataset\n",
    "for i in data.columns:\n",
    "    print(\"The no.of unique values in\",i,\"are: \",data.loc[:,i].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6087c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983dbca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering the project task, and now that we have a general overview of our data, we need \n",
    "# focus our attention on the labels: which are the financially stable and unstable companies? \n",
    "# Let's take a look:\n",
    "\n",
    "print(data['Bankrupt'].value_counts())\n",
    "print('-'* 30)\n",
    "print('Financially stable: ', round(data['Bankrupt'].value_counts()[0]/len(data) * 100,2), '% of the dataset')\n",
    "print('Financially unstable: ', round(data['Bankrupt'].value_counts()[1]/len(data) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d9ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking labels distributions\n",
    "data['Bankrupt'].value_counts().plot.pie(autopct=\"%2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab091468",
   "metadata": {},
   "source": [
    "# we can clearly see how our labels are strongly unbalanced, and this is a the main obstacle that we need to solve to obtain good performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae00150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA & Visualisation\n",
    "\n",
    "for i in data.columns:\n",
    "    plt.figure(figsize=(15,3))\n",
    "    sns.distplot(data.loc[:,i],hist=False)\n",
    "    plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d1968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let Find out if our data is skewed or not.\n",
    "for i in data.columns:\n",
    "    print(\"The skewness of\",i,\"is: \",data.loc[:,i].skew())\n",
    "    print(\"------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d8de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew=[]\n",
    "for i in data.columns:\n",
    "    skew.append(data.loc[:,i].skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de4aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_dict={'features': data.columns, 'skewness':skew}\n",
    "skew_data= pd.DataFrame(skew_dict)\n",
    "skew_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be88c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=skew_data['features'], y=skew_data['skewness'])\n",
    "plt.axhline(y=3, color='r')\n",
    "plt.axhline(y=-3, color='r')\n",
    "plt.axhline(y=0, color='k')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2917fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now a Glance on histogram and Heatmap for the correlation analysis..\n",
    "data.hist(figsize = (35,30), bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7047ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap (Spearman)\n",
    "f, ax = plt.subplots(figsize=(30, 25))\n",
    "mat = data.corr('spearman')\n",
    "mask = np.triu(np.ones_like(mat, dtype=bool))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(mat, mask=mask, cmap=cmap, vmax=1, center=0,# annot = True,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc99935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For More Clear insights We can use Boxplot for numerical features.\n",
    "plt.figure(figsize = (20,20))\n",
    "ax =sns.boxplot(data = data, orient=\"h\")\n",
    "ax.set_title('Description of ranges of data', fontsize = 18)\n",
    "ax.set(xscale=\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e69f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets plot those varibale whose its own value in any company's growth or demotion..\n",
    "\n",
    "f, axes = plt.subplots(ncols=4, figsize=(24,6))\n",
    "\n",
    "sns.boxplot(x='Bankrupt', y=\" Net Income to Total Assets\", data=data, ax=axes[0])\n",
    "axes[0].set_title('Bankrupt vs Net Income to Total Assets')\n",
    "\n",
    "sns.boxplot(x='Bankrupt', y=\" Total debt/Total net worth\", data=data, ax=axes[1]) \n",
    "axes[1].set_title('Bankrupt vs Tot Debt/Net worth Correlation')\n",
    "\n",
    "sns.boxplot(x='Bankrupt', y=\" Debt ratio %\", data=data, ax=axes[2])\n",
    "axes[2].set_title('Bankrupt vs Debt ratio Correlation')\n",
    "\n",
    "sns.boxplot(x='Bankrupt', y=\" Net worth/Assets\", data=data, ax=axes[3])  \n",
    "axes[3].set_title('Bankrupt vs Net Worth/Assets Correlation') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab6e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because Index 4 out of bounds error appear i.e why we are plotting in two times.\n",
    "f, axes = plt.subplots(ncols=4, figsize=(24,6))\n",
    "\n",
    "sns.boxplot(x='Bankrupt', y=\" Working Capital to Total Assets\", data=data, ax=axes[0])\n",
    "axes[0].set_title('Bankrupt vs  working capital to total assets')\n",
    "\n",
    "sns.boxplot(x='Bankrupt', y=\" Cash/Total Assets\", data=data, ax=axes[1])\n",
    "axes[1].set_title('Bankrupt vs cash / total assets')\n",
    "\n",
    "sns.boxplot(x='Bankrupt', y=\" Current Liability to Assets\", data=data, ax=axes[2])\n",
    "axes[2].set_title('Bankrupt vs current liability to assets')\n",
    "\n",
    "sns.boxplot(x='Bankrupt', y=\" Retained Earnings to Total Assets\", data=data, ax=axes[3])\n",
    "axes[3].set_title('Bankrupt vs  Retained Earnings to Total Assets')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352da0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the feature distributions for close to bankrputcy companies\n",
    "\n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize=(24, 6))\n",
    "\n",
    "cash_flow_rate = data[' Net Income to Total Assets'].loc[data['Bankrupt'] == 1].values\n",
    "sns.distplot(cash_flow_rate,ax=ax1, color='#FB8861')\n",
    "ax1.set_title(' Net Income to Total Assets \\n (Unstable companies)', fontsize=14)\n",
    "\n",
    "tot_debt_net = data[' Total debt/Total net worth'].loc[data['Bankrupt'] == 1].values\n",
    "sns.distplot(tot_debt_net ,ax=ax2, color='#56F9BB')\n",
    "ax2.set_title('total debt/tot net worth \\n (Unstable companies)', fontsize=14)\n",
    "\n",
    "\n",
    "debt_ratio = data[' Debt ratio %'].loc[data['Bankrupt'] == 1].values\n",
    "sns.distplot(debt_ratio,ax=ax3, color='#C5B3F9')\n",
    "ax3.set_title('debt_ratio \\n (Unstable companies)', fontsize=14)\n",
    "\n",
    "net_worth_assets = data[' Net worth/Assets'].loc[data['Bankrupt'] == 1].values\n",
    "sns.distplot(net_worth_assets,ax=ax4, color='#C5B3F9')\n",
    "ax4.set_title('net worth/assets \\n (Unstable companies)', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef717e6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize=(24, 6))\n",
    "\n",
    "working_cap = data[' Working Capital to Total Assets'].loc[data['Bankrupt'] == 1].values\n",
    "sns.distplot(working_cap,ax=ax1, color='#FB8861')\n",
    "ax1.set_title('working capitals to total assets \\n (Unstable companies)', fontsize=14)\n",
    "\n",
    "cash_tot_assets = data[' Cash/Total Assets'].loc[data['Bankrupt'] == 1].values\n",
    "sns.distplot(cash_tot_assets ,ax=ax2, color='#56F9BB')\n",
    "ax2.set_title('cash/total assets \\n (Unstable companies)', fontsize=14)\n",
    "\n",
    "\n",
    "asset_liab = data[' Current Liability to Assets'].loc[data['Bankrupt'] == 1].values\n",
    "sns.distplot(asset_liab,ax=ax3, color='#C5B3F9')\n",
    "ax3.set_title('liability to assets \\n (Unstable companies)', fontsize=14)\n",
    "\n",
    "operating_funds = data[' Retained Earnings to Total Assets'].loc[data['Bankrupt'] == 1].values\n",
    "sns.distplot(operating_funds,ax=ax4, color='#C5B3F9')\n",
    "ax4.set_title('retain earnings to total assets \\n (Unstable companies)', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5959d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will try to remove the most extreme outliers (note that you can also impute them with the mean or\n",
    "# the median instead of removing them). This should increase our models' performance.\n",
    "\n",
    "#outlier removal...\n",
    "def outliers_removal(feature,feature_name,dataset):\n",
    "    \n",
    "    # Identify 25th & 75th quartiles\n",
    "\n",
    "    q25, q75 = np.percentile(feature, 25), np.percentile(feature, 75)\n",
    "    print('Quartile 25: {} | Quartile 75: {}'.format(q25, q75))\n",
    "    feat_iqr = q75 - q25\n",
    "    print('iqr: {}'.format(feat_iqr))\n",
    "    \n",
    "    feat_cut_off = feat_iqr * 1.5\n",
    "    feat_lower, feat_upper = q25 - feat_cut_off, q75 + feat_cut_off\n",
    "    print('Cut Off: {}'.format(feat_cut_off))\n",
    "    print(feature_name +' Lower: {}'.format(feat_lower))\n",
    "    print(feature_name +' Upper: {}'.format(feat_upper))\n",
    "    \n",
    "    outliers = [x for x in feature if x < feat_lower or x > feat_upper]\n",
    "    print(feature_name + ' outliers for close to bankruptcy cases: {}'.format(len(outliers)))\n",
    "    #print(feature_name + ' outliers:{}'.format(outliers))\n",
    "\n",
    "    dataset = dataset.drop(dataset[(dataset[feature_name] > feat_upper) | (dataset[feature_name] < feat_lower)].index)\n",
    "    print('-' * 65)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "for col in data:\n",
    "    new_df = outliers_removal(data[col],str(col),data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f673247",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,(ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(24,6))\n",
    "\n",
    "# Boxplots with outliers removed\n",
    "\n",
    "sns.boxplot(x=\"Bankrupt\", y=\" Net Income to Total Assets\", data=new_df,ax=ax1) \n",
    "ax1.set_title(\"Net Income to Total Assets \\n Reduction of outliers\", fontsize=14)\n",
    "\n",
    "sns.boxplot(x=\"Bankrupt\", y=\" Total debt/Total net worth\", data=new_df,ax=ax2) \n",
    "ax2.set_title(\"total debt/total net worth \\n Reduction of outliers\", fontsize=14)\n",
    "\n",
    "sns.boxplot(x=\"Bankrupt\", y=\" Debt ratio %\", data=new_df,ax=ax3) \n",
    "ax3.set_title(\"debt ratio % \\n Reduction of outliers\", fontsize=14)\n",
    "\n",
    "sns.boxplot(x=\"Bankrupt\", y=' Net worth/Assets', data=new_df,ax=ax4) \n",
    "ax4.set_title(\"net worth/assets \\n Reduction of outliers\", fontsize=14)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e83d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,(ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(24,6))\n",
    "\n",
    "# Boxplots with outliers removed\n",
    "\n",
    "sns.boxplot(x=\"Bankrupt\", y=' Working Capital to Total Assets', data=new_df,ax=ax1) \n",
    "ax1.set_title(\"working capital to total assets \\n Reduction of outliers\", fontsize=14)\n",
    "\n",
    "sns.boxplot(x=\"Bankrupt\", y=' Cash/Total Assets', data=new_df,ax=ax2) \n",
    "ax2.set_title(\"cash / total assets \\n Reduction of outliers\", fontsize=14)\n",
    "\n",
    "sns.boxplot(x=\"Bankrupt\", y=' Current Liability to Assets', data=new_df,ax=ax3) \n",
    "ax3.set_title(\"current liability to assets \\n Reduction of outliers\", fontsize=14)\n",
    "\n",
    "sns.boxplot(x=\"Bankrupt\", y=' Retained Earnings to Total Assets', data=new_df,ax=ax4) \n",
    "ax4.set_title(\"Retained Earnings to Total Assets \\n Reduction of outliers\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be34c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_trans(d):\n",
    "    \n",
    "    for col in d:\n",
    "        skew = d[col].skew()\n",
    "        if skew > 0.5 or skew < -0.5:\n",
    "            d[col] = np.log1p(d[col])\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return d\n",
    "\n",
    "data_norm = log_trans(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e483bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Boxplots of the preprocessed numerical features\n",
    "\n",
    "plt.figure(figsize = (20,20))\n",
    "ax =sns.boxplot(data = data_norm, orient=\"h\")\n",
    "ax.set_title('Bank Data Preprocessed Boxplots', fontsize = 18)\n",
    "ax.set(xscale=\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8aa162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    y = df['Bankrupt']\n",
    "    X = df.drop('Bankrupt', axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state=2)\n",
    "    \n",
    "    sc_X = StandardScaler()\n",
    "    X_train = sc_X.fit_transform(X_train)\n",
    "    X_test = sc_X.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca198a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e613b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d853402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts() / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b4ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_models = {\n",
    "    \"Logistic Regression\": LogisticRegression(solver = \"liblinear\", l1_ratio = 0.4),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(weights='distance', metric='euclidean'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Support Vector Machine (LinearSVC)\": LinearSVC(C = 0.3),\n",
    "    \"Support Vector Machine (kernel SVM)\": SVC(kernel = 'rbf', random_state = 0),\n",
    "    \"MLPClassifier\": MLPClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(loss = \"exponential\"),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(n_estimators = 60, learning_rate = 0.2),\n",
    "    \"XgBoost Classifier\": XGB.XGBClassifier(),\n",
    "    \"CatBoost Classifier\": CatBoostClassifier(),\n",
    "    \"LightGBM\": LGBMClassifier()\n",
    "}\n",
    "\n",
    "for name, model in var_models.items():\n",
    "  model.fit(X_train, y_train)\n",
    "  print(name + ' was completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43200f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_results = []\n",
    "\n",
    "for name, model in var_models.items():\n",
    "  results = model.score(X_test, y_test)\n",
    "  var_results.append(results)\n",
    "\n",
    "  print('----------     '+name+'     ----------')\n",
    "\n",
    "  model = var_models[name]\n",
    "  y_test_pred = model.predict(X_test)\n",
    "  print(metrics.classification_report(y_test_pred, y_test))\n",
    "  print(name + ': {:.4f}%'.format(results * 100))\n",
    "  print('Accuracy :{0:0.4f}'.format(metrics.accuracy_score(y_test_pred , y_test))) \n",
    "  print('AUC : {0:0.4f}'.format(metrics.roc_auc_score(y_test_pred , y_test)))\n",
    "  print('Precision : {0:0.4f}'.format(metrics.precision_score(y_test_pred , y_test)))\n",
    "  print('Recall : {0:0.4f}'.format(metrics.recall_score(y_test_pred , y_test)))\n",
    "  print('F1 : {0:0.4f}'.format(metrics.f1_score(y_test_pred , y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db778de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20,8)\n",
    "\n",
    "for i in var_models:\n",
    "    y_pred = var_models[i].predict(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    precision, recall, th = precision_recall_curve(y_test, y_pred,pos_label=1)\n",
    "    plt.plot(fpr, tpr, label= i + ' : {:.4f}'.format(roc_auc_score(y_test, y_pred)))\n",
    "\n",
    "plt.plot([0,1], [0,1], 'k--' )\n",
    "plt.axis([-0.01, 1, 0, 1])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve for Predicting a Bankruptcy')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b23d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "\n",
    "fig = plt.figure(figsize=(25,15))\n",
    "\n",
    "for name, model in var_models.items():\n",
    "    results = model.score(X_test, y_test)\n",
    "    model = var_models[name]\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    arg_test = {'y_true':y_test, 'y_pred':y_test_pred}\n",
    "\n",
    "    conf_mx = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "    heat_cm = pd.DataFrame(conf_mx, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "    heat_cm.index.name = 'Actual'\n",
    "    heat_cm.columns.name = 'Predicted'\n",
    "\n",
    "    plt.subplot(4, 3, a)\n",
    "    fig.subplots_adjust(wspace=0.45, hspace= 0.45)\n",
    "    sns.heatmap(heat_cm, annot=True, fmt='.2f', square=True, annot_kws={\"size\": 14}, cmap = 'PuRd').set_title(name, fontsize = 20)\n",
    "    a = a + 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d272f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# Till now it we are working with original data with any manupulation..\n",
    "# Now with Smote\n",
    "sm = SMOTE(random_state = 42)\n",
    "X_train_smote, y_train_smote = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = y_train_smote)\n",
    "plt.title('Bankrupt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_models_smote = {\n",
    "    \"Logistic Regression\": LogisticRegression(solver = \"liblinear\", l1_ratio = 0.4),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(weights='distance', metric='euclidean'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Support Vector Machine (LinearSVC)\": LinearSVC(C = 0.3),\n",
    "    \"Support Vector Machine (SVC)\": SVC(),\n",
    "    \"MLPClassifier\": MLPClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(loss = \"exponential\"),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(n_estimators = 60, learning_rate = 0.2),\n",
    "    \"XgBoost Classifier\": XGB.XGBClassifier(),\n",
    "    \"CatBoost Classifier\": CatBoostClassifier(),\n",
    "    \"LightGBM\": LGBMClassifier()\n",
    "}\n",
    "\n",
    "for name, model in var_models_smote.items():\n",
    "  model.fit(X_train_smote, y_train_smote)\n",
    "  print(name + ' was completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d390da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_results_smote = []\n",
    "\n",
    "for name, model in var_models_smote.items():\n",
    "  results_smote = model.score(X_test, y_test)\n",
    "  var_results_smote.append(results_smote)\n",
    "\n",
    "  print('----------     '+name+'     ----------')\n",
    "\n",
    "  model = var_models_smote[name]\n",
    "  y_test_pred_smote = model.predict(X_test)\n",
    "  print(metrics.classification_report(y_test , y_test_pred_smote))\n",
    "  print('Accuracy : {:0.4f}'.format(metrics.accuracy_score(y_test , y_test_pred_smote))) \n",
    "  print('AUC : {0:0.4f}'.format(metrics.roc_auc_score(y_test , y_test_pred_smote)))\n",
    "  print('Precision : {0:0.4f}'.format(metrics.precision_score(y_test , y_test_pred_smote)))\n",
    "  print('Recall : {0:0.4f}'.format(metrics.recall_score(y_test , y_test_pred_smote)))\n",
    "  print('F1 : {0:0.4f}'.format(metrics.f1_score(y_test , y_test_pred_smote)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33917054",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20,8)\n",
    "\n",
    "for i in var_models_smote:\n",
    "    y_pred = var_models_smote[i].predict(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    precision, recall, th = precision_recall_curve(y_test, y_pred,pos_label=1)\n",
    "    plt.plot(fpr, tpr, label= i + ' : {:.4f}'.format(roc_auc_score(y_test, y_pred)))\n",
    "\n",
    "plt.plot([0,1], [0,1], 'k--' )\n",
    "plt.axis([-0.01, 1, 0, 1])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve for Predicting a Bankruptcy')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145bc324",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "\n",
    "fig = plt.figure(figsize=(25,15))\n",
    "\n",
    "for name, model in var_models_smote.items():\n",
    "    results = model.score(X_test, y_test)\n",
    "    model = var_models_smote[name]\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    arg_test = {'y_true':y_test, 'y_pred':y_test_pred}\n",
    "\n",
    "    conf_mx = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "    heat_cm = pd.DataFrame(conf_mx, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "    heat_cm.index.name = 'Actual'\n",
    "    heat_cm.columns.name = 'Predicted'\n",
    "\n",
    "    plt.subplot(4, 3, a)\n",
    "    fig.subplots_adjust(wspace=0.45, hspace= 0.45)\n",
    "    sns.heatmap(heat_cm, annot=True, fmt='.2f', square=True, annot_kws={\"size\": 14}, cmap = 'PuRd').set_title(name, fontsize = 20)\n",
    "    a = a + 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2dea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp = MLPClassifier()\n",
    "\n",
    "#params = [{'activation':['tanh','identity','logistic','relu'],'alpha': np.logspace(0.001,0.01,num=100),'solver': ['lbfgs','sgd','adam']}]\n",
    "          \n",
    "#grd = GridSearchCV(estimator=mlp,param_grid=params,cv=3)\n",
    "\n",
    "#grd_model = grd.fit(xtrain,ytrain)\n",
    "          \n",
    "#grd_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcd2bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The result of GridSearchCV is giving the following results:\n",
    "# 'activation': 'tanh', 'alpha': 1.0058783356953453, 'solver': 'sgd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706bdd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, we can say lightbgm and RandomForest is giving good result compare to others..\n",
    "# so we will look into feature importance in this model.\n",
    "rf = RandomForestClassifier()\n",
    "rf_model= rf.fit(X_train_smote, y_train_smote)\n",
    "rf_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d01abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({'Features':data.drop('Bankrupt', axis=1).columns, 'Feature Importances': rf_model.feature_importances_})\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93cad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = importances.sort_values(by='Feature Importances',ascending=False)\n",
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f740ca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "sns.barplot(y='Feature Importances',x='Features',data=imp)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68ae7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp['Features'][0:9].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461905da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64911067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above cell's varibale are some of the most important factors which result in the bankruptcy of a company/organisation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
